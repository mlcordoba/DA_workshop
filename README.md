DATA ANALYTICS
=====================

## 1 - WORK ENVIRONMENT
The objective is to create the work environment, from the support (Jupyter notebook), through the language (Python) and presenting the main tools for the analysis and visualization of the data (Numpy, Pandas and Matplotlib)

### 1.1 Jupyter Notebook :
The notebooks involve the fusion of text editor, programming tool and visualization support, all accessible through the browser. They are currently, de facto, the way by which code is exchanged and results are displayed.

### 1.2 Basic elements of Python :
Python is a programming language with a wider XX path than R, especially for Big Data application. Will be taught how to use basic elements of Python, such as data types (list, arrays, dictionaries), control flows (for loop, if / else), Input / Output data files and how to generate visualizations.

### 1.3 Numpy, Pandas and Matplotlib :
These libraries are the main tools for the analysis and visualization of data. In this section we will go deeper than in section 1.2.


## 2 - DATA EXPLORATION - TIME SERIES
This second block will serve to put into practice as soon as possible what has been learned in block 1 and move on to manage data exploration techniques in a type of data that is very recurrent in the wind / energy sector.

### 2.1 Analysis of electricity demand in Spain :
This type of time series is a good example to practice data management.

### 2.2 Temperature climatology in Spain :
A good case to practice accessing databases on the web using APIs. It will also serve to exercise how to extract from large datasets usefull parameters and how to merge them with the energy demand series and analyze their impact.


## 3 - INSIGHTS INTO DATA INPUT
On numerous occasions the original data set is not able of leading to the best prediction model. To find the best model it is necessary to apply data cleansing techniques, for example, to select those variables that offer greater predictive power, create new variables using others as a starting point to improve the originals or simply eliminate those variables that degrade the system.

### 3.1 Factor analysis / ANOVA :
Two of the most used techniques are presented to extract information on a set of variables and to be able to arrange them according to the impact they have on the dependent variable.

### 3.2 Clustering : The most used techniques are presented (among which K-means stands out) to separate data and categorize them.

### 3.3 Dimension reduction :
The most used techniques are presented (among which the PCA stands out) in order to be able to construct a set of data of reduced dimensions, and therefore manageable, of better characteristics.

### 3.4 Feature Engineering :
Analysis of different practical cases in which the construction of new variables produced an improvement in the prediction.

